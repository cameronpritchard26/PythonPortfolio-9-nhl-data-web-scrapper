{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>NHL Data Web Scraper</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>This web scraper scrapes data from hockey-reference.com for all teams of a particular season. As of now, the scraper only scrapes team data from the 2023-24 NHL Season, but future changes will be made to the scraper to scrape data across multiple seasons as well as scrape player data.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Step 1: Import Dependencies</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import csv\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Step 2: Define Fields Used to Create team_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIELDS = ['Name', 'Division', 'Season', 'AvAge', 'GP', 'W', 'L', 'OL', 'PTS', 'PTS%', 'GF', \n",
    "          'GA', 'SRS', 'SOS', 'GF/G', 'GA/G', 'PP', 'PPO', 'PP%', 'PPA', 'PPOA', \n",
    "          'PK%', 'SH', 'SHA', 'S', 'S%', 'SA', 'SV%', 'PDO', 'SO', 'S%', \n",
    "          'SV%', 'PDO', 'CF', 'CA', 'CF%', 'xGF', 'xGA', 'aGF', 'aGA', 'axDiff', \n",
    "          'SCF', 'SCA', 'SCF%', 'HDF', 'HDA', 'HDF%', 'HDGF', 'HDC%', 'HDGA', 'HDCO%']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Step 3: Create Starting Soup</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The base URL to scrape from\n",
    "START_SITE = 'https://www.hockey-reference.com/leagues/NHL_2024.html'\n",
    "# Getting the page and creating soup\n",
    "start_response = requests.get(START_SITE)\n",
    "start_soup = BeautifulSoup(start_response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Step 4: Get the Links to Each Team's Page for the Season</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the links to the Eastern Conference teams\n",
    "eastern_conference_teams = start_soup.select(selector='table#standings_EAS tr th a')\n",
    "eastern_conference_team_links = [team.get('href') for team in eastern_conference_teams]\n",
    "# Getting the links to the Western Conference teams\n",
    "western_conference_teams = start_soup.select(selector='table#standings_WES tr th a')\n",
    "western_conference_team_links = [team.get('href') for team in western_conference_teams]\n",
    "# Combining the two lists\n",
    "team_links = eastern_conference_team_links + western_conference_team_links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Future Tasks: </h2>\n",
    "<ul>\n",
    "<li>Properly write to csv</li>\n",
    "<li>Add capacity for past seasons</li>\n",
    "<li>Prevent timing out website</li>\n",
    "<li>Collect player data</li>\n",
    "<li>Conduct analysis</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>This is testing</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Florida Panthers\n",
      "Atlantic\n"
     ]
    }
   ],
   "source": [
    "current_link = team_links[0]\n",
    "\n",
    "new_site = 'https://www.hockey-reference.com' + current_link\n",
    "response = requests.get(new_site)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "team_name = soup.select(selector='h1 span')[1].text\n",
    "division = soup.select(selector='div#meta div p')[2].text.split(' ')[7][4:]\n",
    "print(team_name)\n",
    "print(division)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average_age 29.5\n",
      "games 82\n",
      "wins 52\n",
      "losses 24\n",
      "losses_ot 6\n",
      "points 110\n",
      "points_pct .671\n",
      "goals 265\n",
      "goals_against 198\n",
      "srs 0.81\n",
      "sos -0.02\n",
      "goals_for_per_game 3.23\n",
      "goals_against_per_game 2.41\n",
      "goals_pp 63\n",
      "chances_pp 268\n",
      "power_play_pct 23.51\n",
      "opp_goals_pp 51\n",
      "opp_chances_pp 291\n",
      "pen_kill_pct 82.47\n",
      "goals_sh 8\n",
      "opp_goals_sh 9\n",
      "shots 2764\n",
      "shot_pct 9.6\n",
      "shots_against 2279\n",
      "save_pct .913\n",
      "pdo 100.6\n",
      "shutouts 8\n",
      "shot_pct_5on5 7.2\n",
      "sv_pct_5on5 .935\n",
      "pdo 100.6\n",
      "corsi_for_5on5 4212\n",
      "corsi_against_5on5 3288\n",
      "corsi_pct_5on5 56.2\n",
      "exp_on_goals_for 166.2\n",
      "exp_on_goals_against 144.8\n",
      "actual_goals 156\n",
      "actual_goals_against 119\n",
      "actual_expected_diff 16\n",
      "sc_for 1889\n",
      "sc_against 1550\n",
      "sc_for_pct 54.9\n",
      "hdsc_for 673\n",
      "hdsc_against 545\n",
      "hdsc_for_pct 55.3\n",
      "hdscgoal_for 51\n",
      "hdsc_shot_pct 7.0\n",
      "hdscgoal_against 57\n",
      "hdsc_opp_shot_pct 9.5\n"
     ]
    }
   ],
   "source": [
    "team_stats = soup.select(selector='table#team_stats tr')[1]\n",
    "for stat in team_stats:\n",
    "    statistic = stat.get('data-stat')\n",
    "    if statistic == 'team_name':\n",
    "        continue\n",
    "    value = stat.text\n",
    "    print(statistic, value)\n",
    "team_analytics = soup.select(selector='table#team_stats_adv tr')[1]\n",
    "for analytic in team_analytics:\n",
    "    statistic = analytic.get('data-stat')\n",
    "    if statistic == 'team_name':\n",
    "        continue\n",
    "    value = analytic.text\n",
    "    print(statistic, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-24\n"
     ]
    }
   ],
   "source": [
    "print(soup.select_one(selector='h1 span').text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Step 5: Scrape Data from Each Team and Write it to team_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Name': 'Florida Panthers', 'Division': 'Atlantic', 'Season': '2023-24', None: '9.5'}\n",
      "{'Name': 'Boston Bruins', 'Division': 'Atlantic', 'Season': '2023-24', None: '10.7'}\n",
      "{'Name': 'Toronto Maple Leafs', 'Division': 'Atlantic', 'Season': '2023-24', None: '9.2'}\n",
      "{'Name': 'Tampa Bay Lightning', 'Division': 'Atlantic', 'Season': '2023-24', None: '10.6'}\n",
      "{'Name': 'Detroit Red Wings', 'Division': 'Atlantic', 'Season': '2023-24', None: '10.0'}\n",
      "{'Name': 'Buffalo Sabres', 'Division': 'Atlantic', 'Season': '2023-24', None: '8.3'}\n",
      "{'Name': 'Ottawa Senators', 'Division': 'Atlantic', 'Season': '2023-24', None: '9.4'}\n",
      "{'Name': 'Montreal Canadiens', 'Division': 'Atlantic', 'Season': '2023-24', None: '7.6'}\n",
      "{'Name': 'New York Rangers', 'Division': 'Metropolitan', 'Season': '2023-24', None: '10.0'}\n",
      "{'Name': 'Carolina Hurricanes', 'Division': 'Metropolitan', 'Season': '2023-24', None: '9.9'}\n",
      "{'Name': 'New York Islanders', 'Division': 'Metropolitan', 'Season': '2023-24', None: '8.0'}\n",
      "{'Name': 'Washington Capitals', 'Division': 'Metropolitan', 'Season': '2023-24', None: '9.8'}\n",
      "{'Name': 'Pittsburgh Penguins', 'Division': 'Metropolitan', 'Season': '2023-24', None: '10.5'}\n",
      "{'Name': 'Philadelphia Flyers', 'Division': 'Metropolitan', 'Season': '2023-24', None: '10.6'}\n",
      "{'Name': 'New Jersey Devils', 'Division': 'Metropolitan', 'Season': '2023-24', None: '10.7'}\n",
      "{'Name': 'Columbus Blue Jackets', 'Division': 'Metropolitan', 'Season': '2023-24', None: '8.9'}\n",
      "{'Name': 'Dallas Stars', 'Division': 'Central', 'Season': '2023-24', None: '11.6'}\n",
      "{'Name': 'Winnipeg Jets', 'Division': 'Central', 'Season': '2023-24', None: '7.4'}\n",
      "{'Name': 'Colorado Avalanche', 'Division': 'Central', 'Season': '2023-24', None: '10.3'}\n",
      "{'Name': 'Nashville Predators', 'Division': 'Central', 'Season': '2023-24', None: '8.4'}\n",
      "{'Name': 'St. Louis Blues', 'Division': 'Central', 'Season': '2023-24', None: '9.0'}\n",
      "{'Name': 'Minnesota Wild', 'Division': 'Central', 'Season': '2023-24', None: '9.4'}\n",
      "{'Name': 'Arizona Coyotes', 'Division': 'Central', 'Season': '2023-24', None: '9.2'}\n",
      "{'Name': 'Chicago Blackhawks', 'Division': 'Central', 'Season': '2023-24', None: '8.7'}\n",
      "{'Name': 'Vancouver Canucks', 'Division': 'Pacific', 'Season': '2023-24', None: '8.9'}\n",
      "{'Name': 'Edmonton Oilers', 'Division': 'Pacific', 'Season': '2023-24', None: '10.0'}\n",
      "{'Name': 'Los Angeles Kings', 'Division': 'Pacific', 'Season': '2023-24', None: '10.1'}\n",
      "{'Name': 'Vegas Golden Knights', 'Division': 'Pacific', 'Season': '2023-24', None: '9.3'}\n",
      "{'Name': 'Calgary Flames', 'Division': 'Pacific', 'Season': '2023-24', None: '8.9'}\n",
      "{'Name': 'Seattle Kraken', 'Division': 'Pacific', 'Season': '2023-24', None: '8.2'}\n",
      "{'Name': 'Anaheim Ducks', 'Division': 'Pacific', 'Season': '2023-24', None: '11.0'}\n",
      "{'Name': 'San Jose Sharks', 'Division': 'Pacific', 'Season': '2023-24', None: '9.8'}\n"
     ]
    }
   ],
   "source": [
    "# Opening team_data.csv for writing\n",
    "with open('team_data.csv', 'w', newline='') as csvfile:\n",
    "    # Writing the header row, in this case the data field names\n",
    "    fieldnames = FIELDS\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    # Going through each team link\n",
    "    for link in team_links:\n",
    "        # Creating a dictionary to store the team's data\n",
    "        data_dict = {}\n",
    "        # Getting the site for the team\n",
    "        new_site = 'https://www.hockey-reference.com' + link\n",
    "        response = requests.get(new_site)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        # Getting the team's name, division, and season and adding it to the dictionary\n",
    "        team_name = soup.select(selector='h1 span')[1].text\n",
    "        division = soup.select(selector='div#meta div p')[2].text.split(' ')[7][4:]\n",
    "        season = soup.select(selector='h1 span')[0].text\n",
    "        data_dict['Name'] = team_name\n",
    "        data_dict['Division'] = division\n",
    "        data_dict['Season'] = season\n",
    "        # Loading the team's stats and analytics tables\n",
    "        team_stats = soup.select(selector='table#team_stats tr')[1]\n",
    "        team_analytics = soup.select(selector='table#team_stats_adv tr')[1]\n",
    "        # Going through each statistic and adding it to the dictionary\n",
    "        for stat in team_stats:\n",
    "            statistic = stat.get('aria-label')\n",
    "            if statistic == 'team_name':\n",
    "                continue\n",
    "            value = stat.text\n",
    "            data_dict[statistic] = value\n",
    "        # Going through each analytic and adding it to the dictionary\n",
    "        for analytic in team_analytics:\n",
    "            statistic = analytic.get('aria-label')\n",
    "            if statistic == 'team_name':\n",
    "                continue\n",
    "            value = analytic.text\n",
    "            data_dict[statistic] = value\n",
    "        # Writing the team's data to team_data.csv\n",
    "        print(data_dict)\n",
    "        # writer.writerow(data_dict)\n",
    "        # Pausing for 5 seconds to avoid overloading the server\n",
    "        time.sleep(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
